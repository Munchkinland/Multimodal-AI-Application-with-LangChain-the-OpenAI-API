# -*- coding: utf-8 -*-
"""Multimodal AI Application with LangChain & the OpenAI API V2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ufvoI2L6nX7CyMTXdiLhqXyQvRtoD1Al

Paso 1: Instalar las bibliotecas necesarias desde la terminal o requirements.txt
"""
#Desde terminal -> pip install -r requirements.txt


"""Paso 3: Importar los paquetes necesarios"""

import os
import glob
import openai
import yt_dlp as youtube_dl
from yt_dlp import DownloadError
import docarray
import pydub
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores.faiss import FAISS
from langchain.document_loaders import TextLoader
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import DocArrayInMemorySearch
from IPython.display import display, Markdown

"""Paso 4: Configurar la clave de API de OpenAI (revisar por variable de entorno)"""

openai.api_key = "your_api_key"

"""Paso 5: Descargar video de YouTube y extraer audio en mp3"""

# Select the video url
youtube_url = "https://www.youtube.com/watch?v=CTl3qVdfVT8"

# Point the Directory to store the downloaded video
output_dir = "content/audio/"

# Config for youtube-dl
ydl_config = {
    "format": "bestaudio/best",
    "postprocessors": [
        {
            "key": "FFmpegExtractAudio",
            "preferredcodec": "mp3",
            "preferredquality": "192",
        }
    ],
    "outtmpl": os.path.join(output_dir, "%(title)s.%(ext)s"),
    "verbose": True
}

# Check if the output directory exists, otherwise create it
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# Print a message indicating which video is being downloaded
print(f"Downloading video from {youtube_url}")

try:
    # Download the video using youtube_dl
    with youtube_dl.YoutubeDL(ydl_config) as ydl:
        ydl.download([youtube_url])

    # Check if the downloaded file is a WebM
    downloaded_file = os.path.join(output_dir, ydl.extract_info(youtube_url, download=False)['title'] + ".webm")
    if os.path.exists(downloaded_file):
        # Extract audio from WebM file using pydub
        sound = pydub.AudioSegment.from_file(downloaded_file, format="webm")
        output_filename = f"{output_dir}/{ydl.extract_info(youtube_url, download=False)['title']}.mp3"
        sound.export(output_filename, format="mp3", bitrate="192k")  # Adjust bitrate if needed

        os.remove(downloaded_file)  # Remove the WebM file after successful extraction
    else:
        print(f"Downloaded audio: {downloaded_file}")

except DownloadError as e:
    # Download error occurred, handle it (e.g., print error message or retry logic)
    print(f"Download failed: {e}")

"""Paso 6: Encontrar archivos de audio descargado"""

# Find all the audio files in the output directory
audio_files = glob.glob(os.path.join(output_dir, "*.mp3"))

# Check if any audio files were found
if audio_files:
  # Select the first audio file in the list
  audio_filename = audio_files[0]
  # Print the name of the selected audio file
  print(audio_filename)
else:
  print("No audio files found in the output directory.")

"""Paso 7: Transcribir el audio utilizando Whisper"""

# Transcribe the audio file to text using OpenAI API
audio_file = audio_filename
output_file = "files/transcripts/transcript.txt"
model = "whisper-1"

print("Converting audio to text...")

with open(audio_file, "rb") as audio:
    response = openai.Audio.transcribe(model, audio)

# Extract the transcript from the response
transcript = response["text"]

# If an output file is specified, save the transcript to a .txt file
if output_file is not None:
    # Create the directory for the output file if it doesn't exist
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    # Write the transcript to the output file
    with open(output_file, "w") as file:
        file.write(transcript)

# Print the transcript to the console to verify if it worked
print(transcript)

"""Paso 8: Crear un TextLoader utilizando LangChain"""

# Initialize the TextLoader with the transcript
loader = TextLoader('files/transcripts/transcript.txt')

# Load the documents using the loader
documents = loader.load()

# Display the first document to verify if it was loaded correctly
display(documents[0])

"""Paso 9: Dividir el texto en fragmentos utilizando el CharacterTextSplitter"""

# Initialize the CharacterTextSplitter with desired settings
text_splitter = CharacterTextSplitter(
    chunk_size=1000,  # Maximum size of each chunk
    chunk_overlap=200  # Overlap between chunks
)

# Split the text into chunks using the text splitter
texts = text_splitter.split_documents(documents)

# Display the first chunk to verify if it was split correctly
display(texts[0])

"""Paso 10: Crear un Ã­ndice FAISS a partir de los fragmentos de texto"""

!pip install faiss-cpu

# Initialize the OpenAI embeddings
embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)

# Create a FAISS index from the text chunks
faiss_index = FAISS.from_texts([text.page_content for text in texts], embeddings)

# Display a message to indicate that the index was created successfully
print("FAISS index created successfully.")

"""Paso 11: Crear una cadena de recuperaciÃ³n de preguntas y respuestas (RetrievalQA) ðŸ‘‰ Subir la variable de entorno para contraseÃ±a al inicio del programa"""

# Initialize the OpenAI chat model
import openai
import os

os.environ["OPENAI_API_KEY"] = "sk-proj-NCeH7elzvrTgjL2rPQJrT3BlbkFJ8MQDCZWYC2inGXbiWaPS"  # Set API key as environment variable
chat_model = ChatOpenAI(model_name="gpt-4")

# Create the RetrievalQA chain
qa_chain = RetrievalQA.from_chain_type(
    llm=chat_model,
    chain_type="stuff",
    retriever=faiss_index.as_retriever()
)

# Display a message to indicate that the RetrievalQA chain was created successfully
print("RetrievalQA chain created successfully.")

"""Paso 12: Preguntar al modelo para probar el retrieval de informaciÃ³n"""

# Ask a sample question using the QA chain
question = "What is the main topic of the video?"
response = qa_chain.run(question)

# Display the response
print(f"Question: {question}")
print(f"Answer: {response}")

# Set the query to be user for the QA system
question = "Who should what this video?"

# Run the question through the RetrievalQA instance and the response

response = qa_chain.run(question)

# Print the response to the console

print(response)

"""Testing question not related with transcript (particular video)

"""

# Set the query to be user for the QA system
question = "Who is the brest football player in the world?"

# Run the question through the RetrievalQA instance and the response

response = qa_chain.run(question)

# Print the response to the console

print(response)

# Set the query to be user for the QA system
question = "How long is the circumference of the earth?"

# Run the question through the RetrievalQA instance and the response

response = qa_chain.run(question)

# Print the response to the console

print(response)
